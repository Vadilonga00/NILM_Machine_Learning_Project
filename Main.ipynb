{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vadilonga00/Progetto_ML/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db66cfa5",
      "metadata": {
        "id": "db66cfa5"
      },
      "source": [
        "Si importano le librerie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72329507",
      "metadata": {
        "id": "72329507"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, recall_score,f1_score\n",
        "from joblib import dump, load"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dad3e9e",
      "metadata": {
        "id": "9dad3e9e"
      },
      "source": [
        "Si importa il dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb20ffc7",
      "metadata": {
        "id": "cb20ffc7"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('25day_dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a689a11",
      "metadata": {
        "id": "5a689a11"
      },
      "source": [
        "Elimino la riga in questione dal momento che l'accensione dei due dispositivi avviene in un solo secondo (possibile errore di campionamento).Non essendo un campione riguardante il test set posso eliminarlo a priori.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a619042",
      "metadata": {
        "id": "8a619042"
      },
      "outputs": [],
      "source": [
        "data.drop(1461218, inplace=True) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a264a4",
      "metadata": {
        "id": "66a264a4"
      },
      "source": [
        "Si aggiunge la colonna delle label, in cui per ogni campione viene associata la classe in base ai consumi relativi ai tre elettrodomestici. Sono state introdotte solamente quattro classi dal momento che non vi sono campioni in cui i dispositivi sono accesi contemporaneamente:\n",
        "\n",
        "0)Tre elettrodomestici spenti\n",
        "\n",
        "1)Lavatrice accesa\n",
        "\n",
        "2)Forno acceso\n",
        "\n",
        "3)Lavastoviglie accesa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9689d7c2",
      "metadata": {
        "id": "9689d7c2"
      },
      "outputs": [],
      "source": [
        "label=[]\n",
        "for i in range(len(data)):\n",
        "    if data['wahing_machine'].iloc[i] == 0 and data['oven'].iloc[i] == 0 and data['dishwasher'].iloc[i] == 0:\n",
        "        label.append(0)\n",
        "    elif data['wahing_machine'].iloc[i] != 0 and data['oven'].iloc[i] == 0 and data['dishwasher'].iloc[i] == 0:\n",
        "        label.append(1)\n",
        "    elif data['wahing_machine'].iloc[i] == 0 and data['oven'].iloc[i] != 0 and data['dishwasher'].iloc[i] == 0:\n",
        "        label.append(2)\n",
        "    else:\n",
        "        data['wahing_machine'].iloc[i] == 0 and data['oven'].iloc[i] == 0 and data['dishwasher'].iloc[i] != 0\n",
        "        label.append(3)\n",
        "data['classe']=label"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f091527c",
      "metadata": {
        "id": "f091527c"
      },
      "source": [
        "Creazione delle 10 fold di Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d30af7c",
      "metadata": {
        "id": "7d30af7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "Test_set1 =data.loc[(data['DateTime']>='2022-01-01') & (data['DateTime']<'2022-01-02')]\n",
        "Test_set2 =data.loc[(data['DateTime']>='2022-01-02') & (data['DateTime']<'2022-01-03')]\n",
        "Test_set3 =data.loc[(data['DateTime']>='2022-01-03') & (data['DateTime']<'2022-01-04')]\n",
        "Test_set4 =data.loc[(data['DateTime']>='2022-01-04') & (data['DateTime']<'2022-01-05')]\n",
        "Test_set5 =data.loc[(data['DateTime']>='2022-01-05') & (data['DateTime']<'2022-01-06')]\n",
        "Test_set6 =data.loc[(data['DateTime']>='2022-01-06') & (data['DateTime']<'2022-01-07')]\n",
        "Test_set7 =data.loc[(data['DateTime']>='2022-01-07') & (data['DateTime']<'2022-01-08')]\n",
        "Test_set8 =data.loc[(data['DateTime']>='2022-01-08') & (data['DateTime']<'2022-01-09')]\n",
        "Test_set9 =data.loc[(data['DateTime']>='2022-01-10') & (data['DateTime']<'2022-01-12')]\n",
        "Test_set10 =data.loc[(data['DateTime']>='2022-01-12') & (data['DateTime']<'2022-01-13 03:17:00')]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b5fc47",
      "metadata": {
        "id": "f0b5fc47"
      },
      "source": [
        "Vengono inizializzate due liste vuote in cui verranno inseriti i valori di f_score e recall per ogni classe (per ogni test set).  Ogni training set utilizza tutti i campioni del dataset ad eccezione di quelli utilizzati nel test set corrente. \n",
        "Per ogni coppia training-test day verranno restituite per ogni singolo dispositivo le prestazioni sulla f_score e recall.\n",
        "Per completezza sono state inserite inoltre la matrice di confusione e il classification_report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53bccf39",
      "metadata": {
        "id": "53bccf39",
        "outputId": "a7cee017-e368-4904-882d-ae772bc6baac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[79419   489    15  1742]\n",
            " [  100  3953     0     0]\n",
            " [  143     0   539     0]\n",
            " [    0     0     0     0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     81665\n",
            "           1       0.89      0.98      0.93      4053\n",
            "           2       0.97      0.79      0.87       682\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97     86400\n",
            "   macro avg       0.71      0.68      0.70     86400\n",
            "weighted avg       0.99      0.97      0.98     86400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[76745   917   135   472]\n",
            " [  474  6533     0     1]\n",
            " [   58     0  1065     0]\n",
            " [    0     0     0     0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     78269\n",
            "           1       0.88      0.93      0.90      7008\n",
            "           2       0.89      0.95      0.92      1123\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98     86400\n",
            "   macro avg       0.69      0.72      0.70     86400\n",
            "weighted avg       0.98      0.98      0.98     86400\n",
            "\n",
            "CM:\n",
            "[[78189   920   821  1165]\n",
            " [   47   967    10     0]\n",
            " [    0     1   703     0]\n",
            " [  375   126     0  3076]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.98     81095\n",
            "           1       0.48      0.94      0.64      1024\n",
            "           2       0.46      1.00      0.63       704\n",
            "           3       0.73      0.86      0.79      3577\n",
            "\n",
            "    accuracy                           0.96     86400\n",
            "   macro avg       0.66      0.94      0.76     86400\n",
            "weighted avg       0.97      0.96      0.96     86400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[80334   206   242   973]\n",
            " [    0     0     0     0]\n",
            " [  379  1341  2923     2]\n",
            " [    0     0     0     0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     81755\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.92      0.63      0.75      4645\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.96     86400\n",
            "   macro avg       0.48      0.40      0.43     86400\n",
            "weighted avg       0.99      0.96      0.98     86400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[81698   697     4   336]\n",
            " [   89  3576     0     0]\n",
            " [    0     0     0     0]\n",
            " [    0     0     0     0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     82735\n",
            "           1       0.84      0.98      0.90      3665\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.99     86400\n",
            "   macro avg       0.46      0.49      0.47     86400\n",
            "weighted avg       0.99      0.99      0.99     86400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[81204  1004    21   193]\n",
            " [    0     0     0     0]\n",
            " [    0     0     0     0]\n",
            " [   36    35     0  3907]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     82422\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.95      0.98      0.97      3978\n",
            "\n",
            "    accuracy                           0.99     86400\n",
            "   macro avg       0.49      0.49      0.49     86400\n",
            "weighted avg       1.00      0.99      0.99     86400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[79736   573   118   529]\n",
            " [  200  3057     1     0]\n",
            " [  648     2  1518    18]\n",
            " [    0     0     0     0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     80956\n",
            "           1       0.84      0.94      0.89      3258\n",
            "           2       0.93      0.69      0.79      2186\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98     86400\n",
            "   macro avg       0.69      0.65      0.67     86400\n",
            "weighted avg       0.98      0.98      0.98     86400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[79152   455   193  1639]\n",
            " [   90  4065     0     0]\n",
            " [  496    53   257     0]\n",
            " [    0     0     0     0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98     81439\n",
            "           1       0.89      0.98      0.93      4155\n",
            "           2       0.57      0.32      0.41       806\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97     86400\n",
            "   macro avg       0.61      0.57      0.58     86400\n",
            "weighted avg       0.98      0.97      0.97     86400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[166005    946    599    681]\n",
            " [   123   2667      0      0]\n",
            " [   597      0   1182      0]\n",
            " [     0      0      0      0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99    168231\n",
            "           1       0.74      0.96      0.83      2790\n",
            "           2       0.66      0.66      0.66      1779\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.98    172800\n",
            "   macro avg       0.60      0.65      0.62    172800\n",
            "weighted avg       0.99      0.98      0.99    172800\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CM:\n",
            "[[89734   498   278  1943]\n",
            " [  262  4099     0     0]\n",
            " [   36     1  1369     0]\n",
            " [    0     0     0     0]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     92453\n",
            "           1       0.89      0.94      0.92      4361\n",
            "           2       0.83      0.97      0.90      1406\n",
            "           3       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.97     98220\n",
            "   macro avg       0.68      0.72      0.70     98220\n",
            "weighted avg       0.99      0.97      0.98     98220\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "f_score=[]\n",
        "recall=[]\n",
        "Test_list=[Test_set1, Test_set2, Test_set3, Test_set4, Test_set5, Test_set6,Test_set7, Test_set8,Test_set9, Test_set10]\n",
        "for testing_day in range(len(Test_list)) :\n",
        "    Test_day=pd.DataFrame(Test_list[testing_day])\n",
        "    Training_day=data.drop(Test_day.index,axis=0)\n",
        "    \n",
        "    #Si eliminano i campioni in cui la potenza attiva è minore della potenza consumata dal singolo dispositivo\n",
        "    inc=Training_day[(Training_day['ActivePower']< Training_day['oven']) | (Training_day['ActivePower']< Training_day['dishwasher']) | (Training_day['ActivePower']< Training_day['wahing_machine'])].index\n",
        "    Training_day.drop(inc, axis=0)\n",
        "    \n",
        "    X_train=Training_day.drop(['DateTime','oven', 'dishwasher', 'wahing_machine','ReactivePower','classe'],axis=1)\n",
        "    Y_train=Training_day.iloc[:,-1]\n",
        "    \n",
        "    #Viene eseguita una compressione del training set prendendo un campione ogni 5 secondi. \n",
        "    #Ogni singolo campione possiederà come valori delle features il valore medio calcolato dai 5 campioni presi.\n",
        "    xtrain=X_train.groupby(np.arange(len(X_train))//5).mean()\n",
        "    #Analogo ragionamento viene applicato alla colonna delle label, solamente che la metrica statistica utilizzata è la moda\n",
        "    ytrain=Y_train.groupby(np.arange(len(Y_train))//5).agg(lambda x:x.value_counts().index[0])\n",
        "    \n",
        "   \n",
        "    X_test=Test_day.drop(['DateTime','oven', 'dishwasher', 'wahing_machine','ReactivePower','classe'],axis=1)\n",
        "    Y_test=Test_day.iloc[:,-1]\n",
        "\n",
        "    \n",
        "    #Per evitare lo sbilanciamento delle classi è stata realizzata una tecnica di undersampling sul training set per ridurre i campioni di classe maggioritaria.\n",
        "    classe0,classe1,classe2,classe3=ytrain.value_counts(sort=False)\n",
        "    sampling_strategy = {0: 10000, 1: 10000, 2: classe2, 3: classe3}\n",
        "    rus = RandomUnderSampler(sampling_strategy=sampling_strategy)\n",
        "    X_res, y_res = rus.fit_resample(xtrain, ytrain)\n",
        "    \n",
        "    \n",
        "    #Si addestra il modello con i parametri ottenuti utilizzando la griglia GridSearchCv e si salvano i modelli per ogni singola fold\n",
        "    modello=RandomForestClassifier(n_estimators=60, max_depth=20, max_features='sqrt', random_state=1)\n",
        "    modello.fit(X_res,y_res)\n",
        "    dump(modello, f'./Modello/model{testing_day+1}.sav')\n",
        "    pred=modello.predict(X_test)\n",
        "    \n",
        "    \n",
        "    #Si valutano le prestazioni del classificatore addestrato, utilizzando i diversi test set\n",
        "    r = recall_score(Y_test,pred, average= None) \n",
        "    f = f1_score(Y_test,pred, average= None)\n",
        "    f_score.append(f)\n",
        "    recall.append(r)\n",
        "    \n",
        "    print(\"CM:\\n\" + str(confusion_matrix(Y_test,pred)) + \"\\n\")\n",
        "    print(classification_report(Y_test,pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35e1f4fe",
      "metadata": {
        "id": "35e1f4fe"
      },
      "source": [
        "Una volta trovati i valori per recall e f1_score dei singoli dispositivi (per ogni test set) vado a calcolare i valori medi per ottenere le metriche desiderate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f3e9b0",
      "metadata": {
        "id": "a9f3e9b0"
      },
      "outputs": [],
      "source": [
        "#f_score_res=pd.DataFrame(f_score).replace(0,np.nan)\n",
        "#print(\"F1_score_Class:\\n\" + str(f_score_res.mean(axis=0, skipna=True)))\n",
        "#recall_res=pd.DataFrame(recall).replace(0,np.nan)\n",
        "#print(\"\\nRecall_Class:\\n\" + str(recall_res.mean(axis=0, skipna=True)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb5ce96f",
      "metadata": {
        "id": "eb5ce96f"
      },
      "source": [
        "Si calcola infine la recall media e la f1_score media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f3e6b2",
      "metadata": {
        "id": "69f3e6b2"
      },
      "outputs": [],
      "source": [
        "#f_score_res=pd.DataFrame(f_score).mean(skipna=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1352239b",
      "metadata": {
        "id": "1352239b"
      },
      "outputs": [],
      "source": [
        "#f_score_res=pd.DataFrame(f_score).replace(0,np.nan)\n",
        "#print(\"F1_score_Mean:\\n\" + str((f_score_res.mean(axis=0, skipna=True)).mean()))\n",
        "#recall_res=pd.DataFrame(recall).replace(0,np.nan)\n",
        "#print(\"\\nRecall_Mean:\\n\" + str((recall_res.mean(axis=0, skipna=True)).mean()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b0da43",
      "metadata": {
        "id": "f4b0da43"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}